{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "\n",
    "import jax\n",
    "from jax import jit\n",
    "import jax.numpy as np\n",
    "from jax.experimental import stax, optimizers\n",
    "from jax.experimental.stax import Dense, elementwise\n",
    "\n",
    "import numpy as onp\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from activations import sigmoid\n",
    "from losses import create_loss, crossentropy as cse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tanh = elementwise(np.tanh)\n",
    "Sigmoid = elementwise(sigmoid)\n",
    "\n",
    "init_random_params, net = stax.serial(\n",
    "    Dense(3), Tanh,\n",
    "    Dense(1), Sigmoid)\n",
    "\n",
    "loss = create_loss(net, cse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_inputs(inputs, params):\n",
    "    \"\"\"Tests all possible xor inputs and outputs\"\"\"\n",
    "    predictions = [int(net(params, inp) > 0.5) for inp in inputs]\n",
    "    for inp, out in zip(inputs, predictions):\n",
    "        print(inp, '->', out)\n",
    "    return (predictions == [onp.bitwise_xor(*inp) for inp in inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_grad = jax.jit(jax.vmap(jax.grad(loss), in_axes=(None, 0, 0), out_axes=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(i, opt_state, batch):\n",
    "    params = get_params(opt_state)\n",
    "    x, y = batch\n",
    "    all_grads = loss_grad(params, x, y)\n",
    "    \n",
    "    for i, grads in enumerate(all_grads):\n",
    "        if len(grads) > 0:\n",
    "            all_grads[i] = tuple(np.mean(g, axis=-1) for g in grads)\n",
    "        else:\n",
    "            all_grads[i] = ()\n",
    "    return opt_update(i, all_grads, opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.sgd(0.5)\n",
    "_, init_params = init_random_params(rng, (-1, 2))\n",
    "opt_state = opt_init(init_params)\n",
    "itercount = itertools.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Iteration 0\n",
      "2\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 0\n",
      "[1 1] -> 1\n",
      "Iteration 100\n",
      "2\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 0\n",
      "[1 1] -> 1\n",
      "Iteration 200\n",
      "2\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 0\n",
      "[1 1] -> 0\n",
      "Iteration 300\n",
      "2\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 0\n",
      "[1 1] -> 0\n",
      "Iteration 400\n",
      "2\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 500\n",
      "2\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 600\n",
      "2\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 1\n",
      "Iteration 700\n",
      "2\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 0\n",
      "[1 1] -> 0\n",
      "Iteration 800\n",
      "2\n",
      "[0 0] -> 0\n",
      "[0 1] -> 1\n",
      "[1 0] -> 1\n",
      "[1 1] -> 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting training...\")\n",
    "\n",
    "for n in itertools.count():\n",
    "    x = inputs[onp.random.choice(inputs.shape[0], size=100)]\n",
    "    y = onp.bitwise_xor(x[:, 0], x[:, 1])\n",
    "    batch = (x, y)\n",
    "\n",
    "    opt_state = update(next(itercount), opt_state, batch)\n",
    "\n",
    "    params = get_params(opt_state)\n",
    "    # Every 100 iterations, check whether we've solved XOR\n",
    "    if not n % 100:\n",
    "        print('Iteration {}'.format(n))\n",
    "        if test_all_inputs(inputs, get_params(opt_state)):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(DeviceArray([[-0.01391013, -4.10821438,  4.13606787],\n",
       "               [ 1.75739849, -2.34439468, -2.19377661]], dtype=float32),\n",
       "  DeviceArray([-0.76694047,  0.76179659,  1.33399212], dtype=float32)),\n",
       " (),\n",
       " (DeviceArray([[-2.20377231],\n",
       "               [-3.73760915],\n",
       "               [-3.45536518]], dtype=float32),\n",
       "  DeviceArray([-0.12238508], dtype=float32)),\n",
       " ()]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_params(opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
